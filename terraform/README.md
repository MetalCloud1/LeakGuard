<h1 align="center">
Terraform ‚Äî Infrastructure for MicroForge (infra/terraform)
</h1>

This README explains what the provided Terraform configuration does, how to use it, and important operational / security notes. It's written to be practical and ready for an open-source template: clear commands, examples, and recommendations so contributors can provision the required AWS + Kubernetes resources for the MicroForge stack.

<h2 align="center">
‚úÖ Overview (what this module creates)
</h2>

The terraform code you provided provisions the following resources:

* **AWS RDS (Postgres)** (`aws_db_instance.authdb`)

    * Creates a Postgres instance and a randomly generated password (`random_password.db_password`).

* **AWS Secrets Manager secret** (`aws_secretsmanager_secret.db_secret`)

    * Stores DB credentials (username, generated password, db name) as JSON via `aws_secretsmanager_secret_version`.

* **Kubernetes** resources (via the `kubernetes` provider connected to EKS):

    * Namespaces per service (loop on `var.services`).

    * Deployments and Services for each service in `var.services` (readiness/liveness probes, resources).

* **Monitoring** (Helm releases installed into `monitoring` namespace):

    * `prometheus` (prometheus-community helm chart)

    * `loki` (loki-stack)

    * `grafana` (grafana chart) ‚Äî `grafana-values.yaml` is loaded by the helm_release.

* **Outputs**

    * `db_endpoint` (RDS address)

    * `db_secret_arn` (ARN of the secretsmanager secret)

The module is intentionally opinionated (creates auth-service and users-api by default) but parameterized (you can change the services variable).

<h2 align="center">
üîßPrerequisites
</h2>

* Terraform **v1.4+** recommended. Add a `required_version` / `required_providers` block in your root module.

* AWS CLI configured locally (or CI) with credentials that can create RDS, Secrets Manager, IAM and EKS read access.

* An existing **EKS cluster** (name provided in `eks_cluster_name`), and the caller must be able to access its API to let the `kubernetes` provider create resources.

* Helm client (for local check) ‚Äî not required for Terraform to run, but helps debugging.

* `grafana-values.yaml` present in same folder (referenced by `helm_release.grafana`).

* Recommended: remote state backend (S3) + state locking (DynamoDB).

<h2 align="center">

üî¢Variables & example `terraform.tfvars`

</h2>

`terraform.tfvars.example` shows which values you should provide. The important variables:

* `aws_region`, `eks_cluster_name`, `aws_secret_name`

* DB: `db_name`, `db_username`, `db_instance_class`, `db_storage`, `db_multi_az`

* App config: `app_image`, `app_replicas`, `app_port`

* `services` is defined as a list of objects (name, image, port, replicas).

* ‚ö†Ô∏èUse a copy `terraform.tfvars` (**never commit secrets**):

```bash
# edit terraform.tfvars with real values (do NOT commit)
cp terraform.tfvars.example terraform.tfvars
```

Alternatively you can pass `-var` or `-var-file` in CLI.

<h2 align="center">

‚ñ∂Ô∏èQuickstart ‚Äî local commands

</h2>

Execute from the `terraform` directory.

1. Initialize

```bash
terraform init
```

2. Validate / plan

```bash
terraform validate
terraform plan -var-file=terraform.tfvars -out=plan.tfplan
```

3. Apply (review plan first)

```bash
terraform apply "plan.tfplan"
# Or directly (less recommended):
terraform apply -var-file=terraform.tfvars
```

4. Destroy (if needed)

```bash
terraform destroy -var-file=terraform.tfvars
```

Tip: Use `-target` only for emergency/partial changes. Prefer full plan/apply.

<h2 align="center">

üîêSecrets & Security

</h2>

* The DB password is generated by `random_password.db_password` and stored in Secrets Manager. Terraform writes the secret JSON via `aws_secretsmanager_secret_version.`

* Do not store `terraform.tfvars` with production credentials in Git. Use environment variables or a CI secret store.

* Production: Use an S3 backend + DynamoDB lock for Terraform state:

    * `terraform { backend "s3" { bucket = "your-tfstate" key = "microforge/terraform.tfstate" region = "us-west-2" } }`

    * Create a DynamoDB table for state locking.

* Rotate DB passwords by updating `random_password` constraints or by running a rotation workflow that replaces the secret and updates RDS credentials accordingly.

* `skip_final_snapshot = true` in `aws_db_instance.authdb` is unsafe for production. Consider setting `skip_final_snapshot = false` and `configuring final_snapshot_identifier.`

<h2 align="center">

‚ö†Ô∏èImportant operational notes & caveats

</h2>

* **Kubernetes provider:** this configuration uses `data "aws_eks_cluster"` + `data "aws_eks_cluster_auth"` to retrieve EKS endpoint and token. That means:

    * Terraform must run with AWS credentials that have `eks:DescribeCluster` for the cluster.

    * The generated token is short-lived ‚Äî running long operations is fine, but if you run Terraform from ephemeral CI runners be sure credentials are present.

* **Helm Releases:** `helm_release` installs Prometheus/Loki/Grafana. The `grafana-values.yaml` file must exist and be correct. Helm chart versions are not pinned here ‚Äî pin chart versions in production.

* **RDS public accessibility:** this module sets `publicly_accessible = false`. Ensure your DB is reachable from the EKS nodes (VPC, subnets, security groups).

* **IAM & IRSA:** the Terraform module reads an IAM role ARN from variables in templates. To enable IAM roles for service accounts (IRSA) you must create the IAM role & OIDC trust separately or add IRSA provisioning to Terraform.

* **Service ports mapping:** Deployments expose `target_port = each.value.port` and service maps port 80 ‚Üí `target_port`. If your containers expect other ports, update `var.services`.

<h2 align="center">

üß©How to add / modify services

</h2>

`var.services` is a list of objects. Example from your `variables` default:

```hcl
variable "services" {
  type = list(object({
    name     = string
    image    = string
    port     = number
    replicas = number
  }))
  default = [
    { name = "auth-service", image = var.app_image, port = var.app_port, replicas = var.app_replicas },
    { name = "users-api",  image = "gilbr/users-api:latest", port = 8000, replicas = 1 }
  ]
}
```

To add a new service:

1. Edit `terraform.tfvars` (or pass `-var`):

```hcl
services = [
  { name = "auth-service", image = "123456.dkr.ecr.us-west-2.amazonaws.com/auth-service:v1.0.0", port = 8000, replicas = 2 },
  { name = "users-api", image = "gilbr/users-api:latest", port = 8000, replicas = 1 },
  { name = "orders-api", image = "myrepo/orders-api:0.1.0", port = 8080, replicas = 2 }
] 
```

2. `terraform plan` and `terraform apply`.

Terraform will create a namespace, deployment and service for each entry. If you change an existing `image`, Terraform will update the `kubernetes_deployment` resource and Kubernetes will roll out the update.



<h2 align="center">

üîÅRetrieving the DB secret (examples)

</h2>

You can read the secret after `apply`:

```bash
aws secretsmanager get-secret-value --secret-id <YOUR_SECRET_NAME> --region us-west-2 \
  --query SecretString --output text | jq .
```

This returns JSON like:

```json
{
  "username": "authuser",
  "password": "generated-password",
  "db_name": "authdb"
}
```
Your application (Kubernetes deployments) should be configured to read DB credentials from AWS Secrets Manager (via IRSA + code that calls Secrets Manager) in production, and use local environment variables or Kubernetes Secrets in dev.

<h2 align="center">

üì§Outputs

</h2>

* `db_endpoint` ‚Äî RDS endpoint address (useful to connect tools / psql).

* `db_secret_arn` ‚Äî ARN of the Secrets Manager secret created by Terraform.

Use `terraform output db_endpoint` after apply to fetch them locally.

<h2 align="center">

üì¶Helm / Grafana values

</h2>

The `helm_release.grafana` uses `file("grafana-values.yaml")`. Keep that file in the same directory and do not commit production credentials inside it. Use Helm value injection with CI or pass values via `--values` that reference Kubernetes Secrets.

<h2 align="center">

üîÑRecommended CI/CD integration

</h2>

* In GitHub Actions, use `aws-actions/configure-aws-credentials` to provide AWS credentials securely from secrets, then run:

```bash
terraform init -backend-config=...
terraform plan -var-file=terraform.tfvars -out=plan.tfplan
terraform apply plan.tfplan
```
* Ensure the runner role/account has IAM permissions for RDS, Secrets Manager, EKS Describe, Helm / Kubernetes apply (through kubernetes provider).

* For safety, restrict `apply` in CI to protected branches or manual approval workflows.

<h2 align="center">

üîÑUpgrades, rollbacks & state management

</h2>

* **Back up state before large changes.**

* Use `terraform plan` to inspect the impact of changes (e.g., scaling replicas vs replacing resources).

* For RDS major version upgrades or engine replacements, prefer manual maintenance windows.

* If `aws_db_instance` must be recreated, RDS snapshots and restore procedures should be in place (do not rely on `skip_final_snapshot = true` in prod).


<h2 align="center">

‚úÖBest practices

</h2>

* Use **remote state (S3) + DynamoDB for locks**.

* Pin provider and helm chart versions.

* Do not commit secrets to repo; use `terraform.tfvars` locally and CI secrets in pipelines.

* Avoid `skip_final_snapshot = true` in production.

* Use semantic image tags (avoid `latest`) and use image scanning/policy in CI.

* Use `terraform workspace` (or separate state per environment) for `dev/staging/` prod.

<h2 align="center">

üîçTroubleshooting

</h2>

* Kubernetes provider auth errors: validate EKS cluster name and AWS credentials. `aws eks update-kubeconfig` locally helps to debug.

* Helm release failures: check `helm` logs in Terraform output and verify `grafana-values.yaml` format.

* RDS creation fails: check subnet group, DB instance class and VPC connectivity (EKS nodes must access RDS, security groups).

* Secrets Manager not found: ensure `aws_secret_name` variable and IAM permissions are correct.

<h2 align="center">

‚≠êUseful Commands

</h2>

```bash
# init (with backend)
terraform init

# plan using tfvars
terraform plan -var-file=terraform.tfvars

# apply (recommended: use saved plan)
terraform apply -var-file=terraform.tfvars

# show outputs
terraform output db_endpoint
terraform output db_secret_arn

# get secret via AWS CLI
aws secretsmanager get-secret-value --secret-id "<name>" --region us-west-2 --query SecretString --output text | jq .

```